{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_follow_count = 0\n",
    "total_unfollow_count = 0\n",
    "logger = logging.getLogger('twitter_logger')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"\"\n",
    "password = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions() \n",
    "options.add_argument(\"start-maximized\")\n",
    "options.add_argument(\"--auto-open-devtools-for-tabs\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "driver = webdriver.Chrome(options=options, executable_path='chromedriver4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_login(username, password):\n",
    "    if type(username) is not str or type(password) is not str:\n",
    "        return\n",
    "    url = \"https://twitter.com/i/flow/login\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('//*[@id =\"react-root\"]/div/div/div/main/div/div/div/div[2]/div[2]/div/div[5]/label/div/div[2]/div/input').send_keys(username)\n",
    "    driver.find_element_by_xpath('//*[@id =\"react-root\"]/div/div/div/main/div/div/div/div[2]/div[2]/div/div[6]').click()\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('//*[@id =\"react-root\"]/div/div/div/main/div/div/div/div[2]/div[2]/div/div/div/div/div[3]/div/label/div/div[2]/div/input').send_keys(password)\n",
    "    time.sleep(2)\n",
    "    driver.find_element_by_xpath('//*[@id =\"react-root\"]/div/div/div/main/div/div/div/div[2]/div[2]/div[2]/div/div/div/div/div/div[1]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_login(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_followers(username):\n",
    "    url = \"https://twitter.com/\" + username + \"/followers/\"\n",
    "    driver.get(url)\n",
    "    SCROLL_PAUSE_TIME = 1.5\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    followers_list = []\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        for a in driver.find_elements_by_xpath('//div[@aria-label=\"Timeline: Followers\"]//a[@role=\"link\"]'):\n",
    "            url = a.get_property('href')\n",
    "            url = url.replace(\"https://twitter.com/\", \"@\")\n",
    "            if 'search' in url:\n",
    "                continue\n",
    "            if 't.co' in url:\n",
    "                continue\n",
    "            if 'https' in url:\n",
    "                continue\n",
    "            if url not in followers_list:\n",
    "                followers_list.append(url)\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    return followers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Duplicates in List\n",
    "to_follow = list(set([x.lower() for x in to_follow]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_following(username):\n",
    "    url = \"https://twitter.com/\" + username + \"/following/\"\n",
    "    driver.get(url)\n",
    "    SCROLL_PAUSE_TIME = 1.5\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    following_list = []\n",
    "    while True:\n",
    "        for a in driver.find_elements_by_xpath('//div[@aria-label=\"Timeline: Following\"]//a[@role=\"link\"]'):\n",
    "            url = a.get_property('href')\n",
    "            url = url.replace(\"https://twitter.com/\", \"@\")\n",
    "            if 'search' in url:\n",
    "                continue\n",
    "            if 't.co' in url:\n",
    "                continue\n",
    "            if 'https' in url:\n",
    "                continue\n",
    "            if url not in following_list:\n",
    "                following_list.append(url)\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    return following_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfollow_list(username):\n",
    "    unfollowing_list = []\n",
    "    followers = retrieve_followers(username)\n",
    "    following = retrieve_following(username)\n",
    "    for x in following:\n",
    "        if x not in followers:\n",
    "            unfollowing_list.append(x)\n",
    "    return unfollowing_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_information(username):\n",
    "    users_info = pd.DataFrame(columns = [\"Username\", \"Followers\", \"Following\", \"Join Date\", \"Work\", \"Location\", \"Website\", \"Bio\", \"Birthday\"])\n",
    "    try:\n",
    "        website = driver.find_element_by_xpath('//div[contains(@data-testid,\"UserProfileHeader_Items\")]//a[1]').get_attribute(\"href\")\n",
    "    except Exception as e:\n",
    "        website = \"\"\n",
    "    try:\n",
    "        bio = driver.find_element_by_xpath('//div[@data-testid=\"UserDescription\"]').text\n",
    "    except Exception as e:\n",
    "        bio = \"\"\n",
    "    try:\n",
    "        work = driver.find_element_by_xpath('//span[contains(@data-testid, \"Professional\")]').text\n",
    "    except:\n",
    "        work = \"\"\n",
    "    try:\n",
    "        location = driver.find_element_by_xpath('//span[contains(@data-testid, \"Location\")]').text\n",
    "    except:\n",
    "        location = \"\"\n",
    "    try:\n",
    "        birthday = driver.find_element_by_xpath('//span[contains(@data-testid, \"Birthdate\")]').text[5:]\n",
    "    except:\n",
    "        birthday = \"\"\n",
    "    try:\n",
    "        join_date = driver.find_element_by_xpath('//span[contains(@data-testid, \"JoinDate\")]').text[7:]\n",
    "    except:\n",
    "        join_date = ''\n",
    "    try:\n",
    "        followers = driver.find_element_by_xpath(\n",
    "            '//a[contains(@href,\"/followers\")]/span[1]/span[1]').text.replace(\",\", \"\")\n",
    "        following = driver.find_element_by_xpath(\n",
    "            '//a[contains(@href,\"/following\")]/span[1]/span[1]').text.replace(\",\", \"\")\n",
    "        if 'K' in followers:\n",
    "            followers = int(float(followers[:-1]) * 1000)\n",
    "        elif 'M' in followers:\n",
    "            followers = int(float(followers[:-1]) * 1000000)\n",
    "        else:\n",
    "            followers = int(followers)\n",
    "        if 'K' in following:\n",
    "            following = int(float(following[:-1]) * 1000)\n",
    "        elif 'M' in following:\n",
    "            following = int(float(following[:-1] * 1000000))\n",
    "        else:\n",
    "            following = int(following)\n",
    "    except Exception as e:\n",
    "        return\n",
    "    users_info = [username, followers, following, join_date, work, location, website, bio, birthday]\n",
    "    return users_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def follow_from_list(accounts):\n",
    "    unfollowers_list = pd.read_csv('~/Downloads/twitter-data/unfollowing-list.csv')\n",
    "    for account in accounts:\n",
    "        driver.get(\"https://twitter.com/\" + account)\n",
    "        if account in unfollowers_list['Username'].unique() or '@' + account in unfollowers_list['Username'].unique():\n",
    "            logger.info(f\"Account {account} is in the unfollowers list!\")\n",
    "            continue\n",
    "        try:\n",
    "            x = driver.find_element_by_xpath('//div[contains(@data-testid,\"FollowIndicator\")]').text\n",
    "            if x == 'Follows you':\n",
    "                logger.info(f'Account {account} already follows you')\n",
    "                continue\n",
    "        except:\n",
    "            try:\n",
    "                driver.get('https://twitter.com/' + account)\n",
    "                time.sleep(5)\n",
    "                # [username, followers, following, join_date, work, location, website, bio, birthday] = \n",
    "                info = get_user_information(account)\n",
    "                followers = info[1]\n",
    "                following = info[2]\n",
    "                join_date = info[3]\n",
    "                work = info[4]\n",
    "                location = info[5]\n",
    "                website = info[6]\n",
    "                bio = info[7]\n",
    "                birthday = info[8]\n",
    "                elem = driver.find_elements(By.CSS_SELECTOR, '.r-yfoy6g > .r-jwli3a')\n",
    "                global total_follow_count\n",
    "                if followers > 10000:\n",
    "                    print(f'Account {account} is too popular to follow back')\n",
    "                    continue\n",
    "                elif following < 250 and followers > 500:\n",
    "                    print(f'Account {account} is unlikely to follow back')\n",
    "                    continue\n",
    "                elif followers > (following * 2):\n",
    "                    print(f'Account {account} is too picky to follow back')\n",
    "                    continue\n",
    "                elif len(elem) > 0 and (elem[0].text == 'This account doesn’t exist'):\n",
    "                    print(f'Account {account}does not exist.')\n",
    "                    continue\n",
    "                else: \n",
    "                    driver.find_element(By.CSS_SELECTOR, '.css-1dbjc4n:nth-child(1) > .css-18t94o4:nth-child(1) > .css-901oao > .css-901oao > .css-901oao').click()\n",
    "                    time.sleep(10)\n",
    "                    print(f'Successful subscribed to {account}.')\n",
    "                    total_follow_count =  total_follow_count + 1\n",
    "                    if(total_follow_count > 300):\n",
    "                        print(\"Total Follow Count REACHED!\")\n",
    "                        break\n",
    "                    try: \n",
    "                        elem_1 = driver.find_element_by_xpath(\"//div[@data-testid='confirmationSheetConfirm']//span[contains(text(),'Unfollow')]\")\n",
    "                        if 'Unfollow' in elem_1.text:\n",
    "                            print(f'Account {account}is already followed')\n",
    "                            total_follow_count =  total_follow_count - 1\n",
    "                            continue\n",
    "                    except:\n",
    "                        continue\n",
    "            except:   \n",
    "                print(f'Subscribtion to {account} not possible.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an unfollowing list \n",
    "unfollowers_list = pd.DataFrame()\n",
    "# Set the save path for the unfollowing list here\n",
    "PATH = \"\"\n",
    "unfollowers_list.to_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfollow_from_list(unfollowing_list):\n",
    "    # Create an Unfollowing List First\n",
    "    global PATH\n",
    "    unfollowers_list = pd.read_csv(PATH)\n",
    "    users_info = pd.DataFrame(columns = [\"Username\", \"Followers\", \"Following\", \"Join Date\", \"Work\", \"Location\", \"Website\", \"Bio\", \"Birthday\"])\n",
    "    for account in unfollowing_list:\n",
    "        try:\n",
    "            driver.get('https://twitter.com/' + account)\n",
    "            time.sleep(20)\n",
    "            elem = driver.find_elements(By.CSS_SELECTOR, '.r-yfoy6g > .r-jwli3a')\n",
    "            if len(elem) > 0 and (elem[0].text == 'This account doesn’t exist'):\n",
    "                logger.info(f'Account {account} does not exist.')\n",
    "                continue      \n",
    "            try:\n",
    "                x = driver.find_element_by_xpath('//div[contains(@data-testid,\"FollowIndicator\")]').text\n",
    "                logger.info(f'Account {account} already follows you')\n",
    "                if x == 'Follows you':\n",
    "                    continue\n",
    "            except: \n",
    "                # elem_1 = driver.find_elements(By.CSS_SELECTOR, '.r-poiln3 > .r-bcqeeo > .r-qvutc0')\n",
    "                if driver.find_element(By.CSS_SELECTOR, '.css-1dbjc4n:nth-child(1) > .css-18t94o4:nth-child(1) > .css-901oao > .css-901oao > .css-901oao').text == 'Follow':\n",
    "                    logger.info(f'Account {account} is already not followed.')\n",
    "                    continue\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    users_info.loc[len(users_info)] = get_user_information(account)\n",
    "                    driver.find_element(By.CSS_SELECTOR, '.css-1dbjc4n:nth-child(1) > .css-18t94o4:nth-child(1) > .css-901oao > .css-901oao > .css-901oao').click()\n",
    "                    time.sleep(10)\n",
    "                    driver.find_element_by_xpath(\"//div[@data-testid='confirmationSheetConfirm']//span[contains(text(),'Unfollow')]\").click()\n",
    "                    global total_unfollow_count\n",
    "                    total_unfollow_count =  total_unfollow_count + 1\n",
    "                    time.sleep(2)\n",
    "        except:   \n",
    "            logger.info('Exception') \n",
    "    unfollowers_list = pd.concat([unfollowers_list, users_info], ignore_index = True)\n",
    "    unfollowers_list.to_csv(\"~/Downloads/twitter-data/unfollowing-list.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
